{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DdR-ZvMec6eb"
      },
      "outputs": [],
      "source": [
        "pip install -q langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install --upgrade langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install -q langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK3uUFzydB2p"
      },
      "outputs": [],
      "source": [
        "pip install -q google-generativeai chromadb pypdf  bs4 streamlit docx2txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install langchain --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1Op3VpbdEfG"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "from dotenv import load_dotenv ,find_dotenv\n",
        "load_dotenv(find_dotenv(), override=True)\n",
        "if os.environ:\n",
        "    for api_key in os.environ:\n",
        "        if \"API_KEY\" in api_key:\n",
        "            print(api_key)\n",
        "else:\n",
        "    import getpass\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"GOOGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQ7PPjamdtIF"
      },
      "outputs": [],
      "source": [
        "# from pprint import pprint\n",
        "from typing import List\n",
        "def load_docs_locally(files:List[str]=[]):\n",
        "\n",
        "    import os\n",
        "    os.chdir(os.path.join(BASE_DIR,\"files/\"))\n",
        "    print(f\"current directory: {os.getcwd()}\")\n",
        "    files = [file for file in os.listdir()] if not files else files\n",
        "    # pprint(files)\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for file in files:\n",
        "        _, extension = os.path.splitext(file)\n",
        "        if not file.startswith(\".\"):\n",
        "          match extension:\n",
        "              case \".pdf\":\n",
        "                  from langchain.document_loaders import PyPDFLoader\n",
        "                \n",
        "                  loader = PyPDFLoader(file)\n",
        "                  print(f\"loading pdf {file} ....\")\n",
        "              case \".txt\":\n",
        "                  from langchain.document_loaders import TextLoader\n",
        "                  loader = TextLoader(file, encoding=\"utf-8\")\n",
        "                  print(f\"loading text {file} ....\")\n",
        "              case \".docx\":\n",
        "                  from langchain.document_loaders import Docx2textLoader\n",
        "                  loader = Docx2textLoader(file)\n",
        "                  print(f\"loading docx {file} ....\")\n",
        "              case _:\n",
        "                  print(f\"no such available format such as {extension}\")\n",
        "\n",
        "\n",
        "        data += loader.load()\n",
        "    os.chdir(\"../\")\n",
        "    # pprint(data)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXsSma_8eAwN"
      },
      "outputs": [],
      "source": [
        "def download_file(url:str,filename:str):\n",
        "    import requests,os\n",
        "    binary_file = requests.get(url).content\n",
        "    _,extension = os.path.splitext(url)\n",
        "\n",
        "    with open(f\"files/{filename}{extension}\", 'wb') as f:\n",
        "        f.write(binary_file)\n",
        "\n",
        "    print(f\"done downloading {filename}{extension}\")\n",
        "    return f\"files/{filename}{extension}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwtTRwRIilhz"
      },
      "outputs": [],
      "source": [
        "def load_docs(docs_urls=[\"https://fsciences.univ-setif.dz/main_page/home\"]):\n",
        "    from langchain.document_loaders.async_html import AsyncHtmlLoader\n",
        "    print(\"loading started....\")\n",
        "    loader = AsyncHtmlLoader(docs_urls)\n",
        "    documents = loader.load()\n",
        "    return documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCJmECp1iidn"
      },
      "outputs": [],
      "source": [
        "def clean_html(html_page:str, title:str):\n",
        "    from pprint import pprint\n",
        "    from bs4 import BeautifulSoup\n",
        "    parser = BeautifulSoup(html_page, \"html.parser\")\n",
        "    # pprint(parser.prettify())\n",
        "    with open(f\"files/{title}.txt\", \"w\",encoding=\"utf-8\") as f:\n",
        "        for string in parser.strings:\n",
        "            if string !=\"\\n\":\n",
        "                f.write(string.strip())\n",
        "                f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NiyXTcqiIvj"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "def mass_download(urls:List[str]):\n",
        "  file_titles = []\n",
        "  html_pages = load_docs(urls)\n",
        "  for i,html_page in enumerate(html_pages):\n",
        "      cleaned_file_title = (\n",
        "          urls[i]\n",
        "          .replace(\"/\", \"_\")\n",
        "          .replace(\".\", \"_\")\n",
        "          .replace(\"-\", \"_\")\n",
        "          .replace(\"https:\", \"\")\n",
        "          .replace(\"dz\", \"\")\n",
        "          .replace(\"net\", \"\")\n",
        "          .replace(\"com\", \"\")\n",
        "          .replace(\"org\", \"\")\n",
        "          .replace(\"edu\", \"\")\n",
        "          .strip(\"_\")\n",
        "      )\n",
        "      clean_html(\n",
        "          html_page.page_content,\n",
        "          cleaned_file_title\n",
        "      )\n",
        "      file_titles.append(cleaned_file_title)\n",
        "  return file_titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4Oa8DQ_iXPK",
        "outputId": "6e891f80-ff22-4aa7-aff8-88e4997b8d31"
      },
      "outputs": [],
      "source": [
        "urls = [\n",
        "      \"https://fsciences.univ-setif.dz/main_page/english\",     \n",
        "  ]\n",
        "mass_download(urls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o8orVx8dwOa",
        "outputId": "558cd4cb-1290-4e5a-a12b-6443fa33c8e7"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "BASE_DIR=os.getcwd()\n",
        "docs = load_docs_locally()\n",
        "# pprint(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l_0FSVTd8nY"
      },
      "outputs": [],
      "source": [
        "def chunk_data(docs):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=0)\n",
        "  text = \"\\n\".join([doc.page_content for doc in docs])\n",
        "  # print(text)\n",
        "  chunks = text_splitter.split_text(text)\n",
        "  return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK5pZASReVqN",
        "outputId": "43eec86b-e53a-4f42-c184-b320bcfddae5"
      },
      "outputs": [],
      "source": [
        "chunks = chunk_data(docs)\n",
        "print(f\"{len(chunks)} chunk\")\n",
        "# pprint(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Hr_17xmecb7"
      },
      "outputs": [],
      "source": [
        "def embed_data(chunks):\n",
        "  from langchain.vectorstores.chroma import Chroma\n",
        "  embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "  vector_index = Chroma.from_texts(\n",
        "      chunks,\n",
        "      embedding\n",
        "  ).as_retriever(\n",
        "      search_type=\"similarity\",\n",
        "      search_kwargs={\n",
        "          \"k\":5\n",
        "      }\n",
        "  )\n",
        "  return vector_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNRYWYXDeyP4"
      },
      "outputs": [],
      "source": [
        "def ask_question(query, vector_index):\n",
        "  from langchain.prompts import PromptTemplate\n",
        "  from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "  from langchain.chains import RetrievalQA\n",
        "\n",
        "  template = \"\"\"\n",
        "  use the following pieces of context to answer the question at the end, translate the answer to arabic. if you don't the answer just say that you don't know the answer, don't try to make up an answer, keep the answer as concise as possible\n",
        "  {context}\n",
        "  Question:{question}\n",
        "  \"\"\"\n",
        "  QA_CHAIN_TEMPLATE = PromptTemplate.from_template(template)\n",
        "  chroma_chain = RetrievalQA.from_chain_type(\n",
        "      llm=ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=1),\n",
        "      retriever=vector_index,\n",
        "      return_source_documents=True,\n",
        "      chain_type_kwargs={\n",
        "          \"prompt\":QA_CHAIN_TEMPLATE\n",
        "      },\n",
        "      verbose=True\n",
        "  )\n",
        "\n",
        "#   response = chroma_chain({\"query\":query})\n",
        "#   pprint(response)\n",
        "  response = chroma_chain({\"query\": query})\n",
        "  result = response[\"result\"]\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KDZSk5LhVAT",
        "outputId": "ebfc968f-f19c-4afd-d71d-8bdfce8a9401"
      },
      "outputs": [],
      "source": [
        "vector_index = embed_data(chunks)\n",
        "pprint(vector_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ_4mKYYe61y",
        "outputId": "b18e8523-b0ed-4460-ee66-543736b60ba5"
      },
      "outputs": [],
      "source": [
        "ask_question(input(\"give your query\"), vector_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
